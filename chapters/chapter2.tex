

\chapter{Analysis of Functions on Product Spaces}

In this chapter, we will describe some results concerning functions
on product probability spaces.

\section{Preliminaries}

Let $(\Omega, \mu)$ be a discrete probability space and
$(\Omega^L,\mu^{\otimes L})$ be the corresponding product space. For a function
$f:\Omega^L \rightarrow \R$, the \emph{Efron-Stein decomposition} of $f$ with
respect to the product space is given by
$$ f(x_1,\cdots, x_L) = \sum_{\beta \subseteq [L]} f_\beta(x),$$
where $f_\beta$ depends only on $x_i$ for $i\in \beta$ and 
$$ \forall \beta' \not\supseteq \beta , a \in \Omega^{\beta'}, \E_{x \in
\mu^{\otimes L}} \left[ f_\beta(x) \mid x_{\beta'} = a \right]=0.$$
The $\ell_p$ and $\ell_\infty$ norms of $f$ with respect to the probability space
are defined as
$$\|f\|_p := \E_{x\in \mu^{\otimes L}}\left[f(x)^p\right]^{1/p},
~~~~~~~~~~~~\|f\|_\infty :=\max_{x\in \Omega^{\otimes L}}\left|f(x)\right|.$$ 
For $i \in [L]$, the \emph{influence} of the $i$th
coordinate on $f$ is defined as follows.
$$\Inf_i[f] := \E_{x_1,\cdots, x_{i-1},x_{i+1},\cdots , x_L}\Var_{x_i}[f
(x_1,\cdots, x_L)]  = \sum_{\beta: i\in \beta} \|f_\beta\|^2_2.$$
For an integer $d$, the \emph{degree $d$ influence} is defined as
$$\Inf_i^{\leq d}[f] := \sum_{\beta: i\in \beta, |\beta| \leq d} \|f_\beta\|^2_2.$$

\section{Invariance Principle}
%TODO: Motivate Invariance Principle More

Let $(\Omega^k, \mu)$ be a probability space. Let $\supp(\mu) := \{ x\in \Omega^k 
\mid \mu(x) > 0\}$. 

\begin{definition}[Connected Sets and Distributions] \label{def:connected}
We say that  $S \subseteq \Omega^k$ is 
\emph{connected} if for every $x, y\in S$, there is a sequence of strings 
starting with $x$ and ending with $y$ such that every element in the sequence is
in $S$ and every two adjacent elements differ in exactly one coordinate. 
The probability space is connected if $\supp(\mu)$ is connected.
\end{definition}


\begin{theorem}[{Mossel~\cite[Proposition 6.4]{Mossel2008}}]

	\label{thm:invariance}
	Let $(\Omega^k, \mu)$ be a connected probability space such the minimum probability of
	every atom in $\supp(\mu)$ is at least $\alpha \in \left(0, \frac{1}{2}\right]$.
	 Then there exists 
	continuous functions $\overline{\Gamma} : (0,1)\rightarrow (0,1)$ and 
	$\underline{\Gamma} : (0,1)\rightarrow (0,1)$ such that the following holds: 
	For every $\epsilon>0$, there exists $\tau > 0$ and an integer $d$ such that 
	if a function $f : \Omega^L \rightarrow [0,1]$ satisfies
	%
	$$\forall i\in [n],  \Inf_i^{\leq d} (f) \leq \tau $$
	%
	then 
	%
	$$\underline{\Gamma}\left(\E_\mu[f]\right) -\epsilon \leq \E_{(x_1,\ldots, x_k) \sim \mu}\left[
	\prod_{j=1}^k f(x_j)\right] \leq \overline{\Gamma}\left(\E_\mu[f]\right) + \epsilon.$$
	%
	There exists an absolute constant $C$ such that one can take $\tau = \epsilon^
	{C\frac{\log(\nicefrac{1}{\alpha})\log(\nicefrac{1}{\epsilon})}{\epsilon
	\alpha^2}}$ and $d = \log(\nicefrac{1}{\tau})\log(\nicefrac{1}{\alpha})$.
\end{theorem}

Correlation is a measure of dependence in probability spaces where the sample space
is a product set.

\begin{definition}[Correlated Spaces]
\label{def:correlation}
Let $(\Omega_1 \times \Omega_2, \mu)$ be a finite probability space, the correlation between $\Omega_1$ and $\Omega_2$ with respect to $\mu$ us defined as 
$$\rho(\Omega_1, \Omega_2; \mu) := \mathop{\max}_{\substack{f : \Omega_1 \rightarrow \R, \E[f]  = 0 , \E[f^2]\leq 1 \\ g: \Omega_2 \rightarrow \R, \E[g] = 0 , \E[g^2]\leq 1} }  \E_{(x,y) \sim \mu }[ |f(x)g(y)|] .$$
For a probability space $\left(\prod_{i=1}^k\Omega_i, \mu\right)$, the correlation is given by
$$\rho\left(\prod_{i=1}^k\Omega; \mu\right) := \max_{i \in [k]} \rho\left( \Omega_i, \prod_{ j \in [k], j \neq i} \Omega_i; \mu\right).$$ 
\end{definition}

The following result about correlated spaces is an
adaptation of similar results (see Wenner
\cite[Theorem~3.12]{Wenner2013} and Guruswami \& 
Lee~\cite[Lemma~A.1]{GuruswamiL2015})   to proving
our hardness results.
 
\begin{theorem}

  \label{thm:inv-prin} Let $(\Omega_1^k \times \Omega_2^k, \mu)$ be a
  correlated probability space with correlation $\rho < 1$
   such that the marginal of $\mu$ on any
  pair of coordinates one each from $\Omega_1$ and $\Omega_2$ is a
  product distribution. Let $\mu_1 ,\mu_2$ be the marginals of $\mu$
  on $\Omega_1^k$ and $\Omega_2^k$ respectively. Let $X, Y$ be two
  random $k\times L$ dimensional matrices chosen as follows:
  independently for every $i \in [L]$, the pair of columns $(x^i,y^i)
  \in \Omega_1^k \times \Omega_2^k$ is chosen from $\mu$. Let
  $x_i,y_i$ denote the $i$\th rows of $X$ and $Y$ respectively.  If
  $F: \Omega_1^L \rightarrow [-1,+1]$ and $G: \Omega_2^L \rightarrow
  [-1,+1]$ are functions such that
	$$\tau:= \sqrt{\sum_{i \in [L]}\Inf_i[F]\cdot \Inf_i[G]}  ~\text{ and } ~
	\Gamma := \max \left\{ \sqrt{\sum_{i \in [L]}\Inf_i[F]} , \sqrt{\sum_{i \in 
	[L]}\Inf_i[G]} \right\} \ ,$$ then
		\begin{equation}
		\label{eqn:inv-eqn}
		\abs{ \E_{(X,Y) \in \mu^{\otimes L}} \left[\prod_{i\in [k]}F(x_i) G(y_i)
		\right] - \E_{X \in \mu_1^{\otimes L}} \left[\prod_{i\in [k]}F(x_i)\right]
		\E_{Y \in \mu_2^{\otimes L}} \left[\prod_{i\in [k]}G(y_i)\right] } \leq 
		2^{O(k)} \Gamma \tau.
	\end{equation}
\end{theorem}

\begin{proof}

	We will prove the theorem by using the hybrid argument. For $i \in [L+1]$, let 
	$X^{(i)},Y^{(i)}$ be distributed according to $(\mu_1 \otimes \mu_2)^{\otimes
	 i} \otimes \mu^{\otimes L- i}$. Thus, $(X^{(0)},Y^{(0)}) =
       (X,Y)$ is distributed according to $\mu^{\otimes L}$ while
       $(X^{(L)},Y^{(L)})$ is distributed according to
       $(\mu_1\otimes\mu_2)^{\otimes L}$. For $i \in [L]$, define
	%
	\begin{equation}
		\label{eqn:err}
		\err_i := \abs{ \E_{X^{(i)},Y^{(i)}} \left[\prod_{j=1}^kF(x^{(i)}_j) 
		G(y^{(i)}_j)\right] - \E_{X^{(i+1)},Y^{(i+1)}} \left[\prod_{j=1}^kF(x^
		{(i+1)}_j) G(y^{(i+1)}_j)\right] }.
	\end{equation}
%
	The left hand side of Equation \eqref{eqn:inv-eqn} is upper bounded by $\sum_{i\in [L]} 
	\err_i$.  Now for a fixed $i$,  we will bound $\err_i$. We use the 
	Efron-Stein decomposition of $F,G$ to split them into two
        parts: the part which depends on the 
	$i$th input and the part independent of the $i$th input. 
	%
	$$F= F_0 + F_1 \text{ where } F_0 := \sum_{\alpha : i\notin \alpha} F_\alpha \mbox{ and } 
	F_1 := \sum_{\alpha : i\in \alpha} F_\alpha.$$
	%
	$$G = G_0 + G_1 \text{ where } G_0 := \sum_{\beta : i\notin \beta} G_\beta  \mbox{ and } 
	G_1 := \sum_{\beta : i\in \beta} G_\beta.$$
	%
	Note that $\Inf_i[F] = \|F_1\|^2_2$ and $\Inf_i[G] =
        \|G_1\|_2^2$. Furthermore, the functions $F_0$ and $F_1$ are
        bounded since $F_0(x) = \E_{x^{'}} [F(x^{'}) |
        x^{'}_{[L]\setminus i} = x_{[L]\setminus i} ] \in [-1,+1]$ and
        $F_1(x) = F(x) - F_0(x) \in [-2,+2]$.  For $a \in \{0,1\}^k$,
        let $F_a(X) := \prod_{j =1}^kF_{a_j}(x_j)$.  Similarly
        $G_0,G_1$ are bounded and $G_a$ defined
        analogously. Substituting these definitions in Equation
        \eqref{eqn:err} and expanding the products gives
	% 
	$$\err_i = \abs{ \sum_{a,b \in \{0,1\}^k}\left(  \E_{X^{(i)},Y^{(i)}} 
	\left[F_{a}(X^{(i)}) G_{b}(Y^{(i)})\right]  - \E_{X^{(i+1)},Y^{(i+1)}} \left[
	F_{a}(X^{(i+1)}) G_{b}(Y^{(i+1)})\right]  \right) }.$$
	%
	Since both the distributions are identical on
	$(\Omega_1^k)^{\otimes L}$ and $(\Omega_2^k)^{\otimes L}$, all
	terms with $a = \bar 0$ or $b=\bar 0$ are zero. Because $\mu$
	is uniform on any pair of coordinates on each from the
	$\Omega_1$ and $\Omega_2$ sides, terms with $|a|=|b|=1$ also
        evaluates to zero. Now consider the remaining terms with $ |a|,|b| \geq1,
	|a|+|b| > 2$. Consider one such term where $a_{1},a_2 = 1$ and $b_{1}
	=1$. In this case, by Cauchy-Schwarz inequality we have that
	%
	\begin{align*}
	\begin{split}
		\abs{ \E_{X^{(i-1)},Y^{(i-1)}} \left[F_a(X^{(i-1)}) G_{b}(Y^{(i-1)})\right]}
		 \leq &\sqrt{\E F_1(x_1)^2 G_1(y_1)^2}  \\ &\cdot \|F_1\|_2  \cdot \left\| 
		\prod_{j>2} F_{a_j}\right\|_\infty \cdot \left\| \prod_{j> 1} G_{b_j}\right
		\|_\infty.
	\end{split}
	\end{align*}
	From the facts that the marginal of $\mu$ to any pair of
	coordinates one each from $\Omega_1$ and $\Omega_2$ sides are
	uniform, $\Inf_i[F] = \|F_1\|_2^2$ and
	$|F_0(x)|,|F_1(x)|,|G_0(x)|,|G_1(x)|$ are all bounded by $2$,
	the right side of above becomes
		\begin{align*}
 \sqrt{\E F_1(x_1)^2} \sqrt{\E G_1(y_1)^2} \cdot \|F_1\|_2  \cdot \left\|
		\prod_{j>2} F_{a_j}\right\|_\infty \cdot \left\| \prod_{j> 1} G_{b_j}
		\right\|_\infty \leq  \sqrt{\Inf_i[F]^2 \Inf_i[G]} \cdot 2^{2k} .
	\end{align*}
	%
	All the other terms corresponding to other $(a,b)$ which are
	at most $2^{2k}$ in number, are bounded analogously. Hence,
	%
	\begin{align*}
		\sum_{i \in [L]} \err_i &\leq 2^{4k} \sum_{i \in [L]} \left( \sqrt{\Inf_i[F]
		^2\Inf_i[G]} +\sqrt{\Inf_i[F]\Inf_i[G]^2} \right)\\
		 &= 2^{4k} \sum_{i \in [L]} \sqrt{\Inf_i[F]
		\Inf_i[G]}\left( \sqrt{\Inf_i[F]} +\sqrt{\Inf_i[G]} \right).
	\end{align*}
By	applying the Cauchy-Schwarz inequality, followed by a triangle inequality, we obtain	
 	\begin{align*}
		\sum_{i \in [L]} \err_i&\leq 2^{4k} \sqrt{\sum_{i \in [L]} \Inf_i[F]\Inf_i[G]}\left(\sqrt{\sum_{i \in [L]}  \Inf_i[F]} + \sqrt{\sum_{i \in 
		[L]}  \Inf_i[G]} \right).
	\end{align*}
Thus, proved.
\end{proof}



